{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pynq HDMI Demo\n",
    "\n",
    "This notebook covers a use case of the pynq project for software video processing demos using HDMI.\n",
    "\n",
    "The goal is to capture a monitor using the HDMI in convert it to grayscale and perform an algorithm on the current frame. The result will be displayed on another monitor using HDMI out. We will also add triggers for pushbuttons to interact with the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading base overlay\n",
    "\n",
    "The base Overlay is a bitstream given by pynq usually already present in the Pynq-Z2. It allows us to use peripherals on the board without the need to go through the Vivado design process. In our case, we will use HDMI (in and out) and GPIOS for the buttons.\n",
    "\n",
    "see : https://pynq.readthedocs.io/en/v2.7.0/pynq_overlays/pynqz2/pynqz2_base_overlay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "base = BaseOverlay(\"base.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of HDMI in and out\n",
    "\n",
    "**HDMI cables must be disconnected before running the cell below otherwise the board may crash**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.lib.video import *    # imports constant to configure the hdmi (PIXEL_GRAY)\n",
    "\n",
    "# creating aliases for easier use\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# configure both hdmi to use pixels in grayscale (8 bit = 1 pixel instead of 24 for RGB)\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_out.configure(hdmi_in.mode,PIXEL_GRAY)\n",
    "\n",
    "# the mode attribute contains informations about \n",
    "print(hdmi_in.mode, hdmi_out.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cacheable_frames is a boolean that controls whether frames should be stored in cacheable or non-cacheable memory\n",
    "by default, it is True but setting it to False may increase performance but software librairies may be SLOWER or NOT WORK.\n",
    "\n",
    "see : https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/hdmi_introduction.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.cacheable_frames = False\n",
    "hdmi_in.cacheable_frames = False\n",
    "\n",
    "# starts hdmi peripherals and and waits for the HMDI cables to be CONNECTED to the board\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to import the library \"cv2\" which is providing us an optimized threshold algorithm and a way to add text to an image. The library \"numpy\" is used to process homogeneous arrays in python and the library \"time\" can be used to calculate the number of IPS. We also need to import the function \"allocate\" from pynq. This function allows us to use contiguous memory in python using a numpy like API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynq import allocate\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the variable numframes to 1000 which is enough for us to see the results we want. The buffer for an image needs to be allocated with the right size (screen height * screen width * (bit per pixel / 8)).\n",
    "\n",
    "There is one concerning issue caused by the hardware limitiation of Pynq-Z2. We are not supposed to enter an image with a resolution higher than 720p when using HDMI as it does not meet the official requirement. It causes performance issues on the output monitor. We tried to reduce the frame size of hdmi in down to 800x600 but the outputting (hdmi out) frame size stays unchanged (720p) and we could not figure out the exact reason. We are using grayscale images allowing us to have the data type of each pixel to go from uint32 (24 bits in RGB) to uint8. It makes the image processing simpler but slows down the pixel unpacking and packing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numframes = 1000\n",
    "\n",
    "data_size = (hdmi_in.mode.height* hdmi_in.mode.width)\n",
    "\n",
    "grayscale  = allocate(shape=(data_size,), dtype=np.uint8)\n",
    "output_buffer = allocate(shape=(data_size,), dtype=np.uint8)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each loop, we read the frame from the input into an array. A new output frame with the right resolution and bit per pixel size is requested from the ouput hdmi class using the method `newframe()`. The default output should be gray scale images without any other process.\n",
    "\n",
    "One of the numerous adventages of using python at the PS end is that users do not need to be concerned about for example the addresses of the registries controlling buttons on the card.  When the button 0 is pressed and hold, the frame grayscale will be processed by our own very simple algorithm using numpy (we set the threshold as 127). Likewise, when the button 1 is pressed and hold, PS will execute the function `cv2.threshold(...)`.\n",
    "\n",
    "At last, by using `reshape()`, the output frames takes the same shape as before the `ravel()`. (At this point, as we are using a laptoop screen as hdmi in, the frame aspect ratio can also influence the output result. Not any aspect ratio (like 16:9) is fully supported by pynq and it can lead to an image shift or displacement).\n",
    "\n",
    "With timestamps that we defined(\"start\" and \"end\"), we can also count the fps of output and add it to the output screen using cv2. \n",
    "\n",
    "It is also necessary to free the buffers that we created when we get out of the loop but it should be freed by python when going out of the scope. It still is a good practice in case of a crash or an interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    grayscale[:] = inframe.ravel() # flatten 2d array to 1d\n",
    "    outframe = hdmi_out.newframe()\n",
    "    \n",
    "    mode = \"grayscale\" \n",
    "    \n",
    "    if base.buttons[0].read(): # checking if the button 0 is being pressed\n",
    "        # numpy threshold        \n",
    "        grayscale[grayscale<127] = 0\n",
    "        grayscale[grayscale>127] = 255\n",
    "        mode = \"threshold SW numpy\"    \n",
    "        \n",
    "    if base.buttons[1].read():\n",
    "        # cv2 standard binary threshold\n",
    "        (T, grayscale_cv2) = cv2.threshold(grayscale, 127, 255, cv2.THRESH_BINARY)\n",
    "        grayscale[:] = grayscale_cv2.reshape(grayscale.shape)\n",
    "        mode = \"threshold SW cv2\"\n",
    "        \n",
    "    outframe[:] = grayscale.reshape(*inframe.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    # writing current mode and fps on the output screen\n",
    "    cv2.putText(outframe, text=\"fps :\"+str(int(1 / (end - start))), org=(200,200),fontFace=3, fontScale=3, color=(150,150,150), thickness=5)\n",
    "    cv2.putText(outframe, text=\"mode :\"+mode, org=(200,350),fontFace=3, fontScale=3, color=(150,150,150), thickness=5)\n",
    "    \n",
    "    start = time.time()\n",
    "    inframe.freebuffer()\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    \n",
    "grayscale.freebuffer()\n",
    "output_buffer.freebuffer()\n",
    "outframe.freebuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the record, we came up with a result of 16-18 fps for the mode \"grayscale\", 3-4 fps for the mode \"threshold SW numpy\" and finally 6-8 fps for the mode \"threshold SW cv2\" for 720p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "This cell is used to clean and close the hdmi peripherals at the end of the demo or to reset the demo in case of an issue on the PL side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.stop()\n",
    "hdmi_in.stop()\n",
    "del hdmi_in, hdmi_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
